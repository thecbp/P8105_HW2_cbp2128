R Notebook
================

Preliminary imports
===================

We need to practice our data wrangling and tidying skills, in addition to importing different types of data. Thus, we'll bring in `tidyverse` and `readxl`.

``` r
library(tidyverse)
library(readxl)
library(knitr)
```

Problem 1
=========

This problem requires us to bring in the NYC Transit dataset and clean up the data. The data is contained within a subdirectory of the project, so we'll pull it from there.

``` r
raw_nyc_data = read_csv(file = './data/P1/nyc_subway.csv')
```

`raw_nyc_data` in its current state is far from tidy form. Each route has its own column, and many of the cells in these route columns are missing. Some stations have multiple rows that only differ on the entrance locations, making much of the dataset redundant if we don't care about the entrance details. Lastly, the problem doesn't need many of the columns in the raw dataset, so they can be safely excluded.

As we clean the data, we'll address these issues and end up with a tidy data set.

``` r
tidy_nyc_data = raw_nyc_data %>% 
  janitor::clean_names() %>% 
  gather(data = ., key = route_number, value = route_served, route1:route11, na.rm = TRUE) %>% 
  mutate(can_enter = ifelse(entry == "YES", TRUE, FALSE),
         has_vending = ifelse(vending == "YES", TRUE, FALSE)) %>% 
  select(., station_name, line, route_served, station_latitude, station_longitude, 
         entrance_type, can_enter, has_vending, is_ada = ada) %>% 
  distinct(., station_name, line, route_served, .keep_all = TRUE) %>%
  arrange(., station_name, line) 
```

The cleaning process
--------------------

`tidy_nyc_data` is the result of our tidying process. After fixing up the column names, I gathered all of the route columns so that we get a 1-to-1 correspondence to each station and every route they serve. Gathering the routes removes the multitude of missing values present in the route columns. `entry` and `vending` have been converted into true Boolean variables and have been renamed to be more descriptive of their "yes/no" nature (the same renaming was done to `ada`). I used `select()` to rearrange the columns to give station the main focus, while removing extraneous columns not required in the problem. Since many of the stations have multiple entrances, I used `distinct()` to make sure that each station-to-route pair is unique.

The ending result keeps the station and line information, and each route has its own row. Other station information such as the station location, entrance type, ADA status has been kept. Customers who may need to figure out if they can even enter a particular station or purchase a Metro Card can use the corresponding Boolean columns.

The original dataset had 1868 rows and 32 columns, while the processed dataset has been reduced to 981 rows and 9 columns. Some stations are seen multiple times if they house different lines or serve multiple routes. The data is now in tidy form.

NYC Transit Data Inquiry
------------------------

### How many distinct stations are there?

If each station is identified by the station and line, then we can use the `distinct()` function again. A station is stated to be uniquely identifiable by a station-line combination, so we'll make sure that we remove duplicates based on both of these columns.

``` r
distinct_stations = tidy_nyc_data %>% 
  distinct(., station_name, line, .keep_all = TRUE)
```

`distinct_stations` tells us that there are 465 distinct stations.

### How many stations are ADA compliant?

Using the `is_ada` column, we can inquire how many of the stations are ADA compliant. Since we need to look at distinct stations, we can use the same code from above and just count how many rows in `is_ada` are `TRUE`.

``` r
are_ada_compliant = sum(distinct_stations$is_ada)
```

84 distinct stations are ADA compliant.

### What proportion of station entrances / exits without vending allow entrance?

We are asked to calculate the proportion of station entrances that allow entrance, given that they don't have vending. We can calculate this from our `distinct_stations` dataset.

``` r
without_vending = filter(distinct_stations, distinct_stations$has_vending == FALSE)
is_enterable = sum(without_vending$can_enter == TRUE)
```

The proportion of stations without vending that allow entrance is 0.5555556.

### How many distinct stations serve the A train? How many of them ADA compliant?

I didn't read far enough ahead to realize that I was supposed to be gathering the routes into their own column, so the reformatting has already been done.

``` r
serves_A = filter(distinct_stations, route_served == "A")
ada_compliant_A_trains = sum(serves_A$is_ada == TRUE)
```

The number of distinct stations that serve the A train is 60, and the number of them that are compliant is 17. Uh oh.

Problem 2
=========

This problem asks us to read and clean the Mr. Trash Wheel data set.

![Actual Picture of Me](./me_but_im_mr_trash.jpg)

Loading Mr. Trash Data
----------------------

``` r
raw_trash_data = read_xlsx('./data/P2/water_wheel.xlsx',
                  range = "A2:N213") # Read in only data, not notes
```

`raw_trash_data` is worthy of its namesake. The data has some summary rows that give the cumulative monthly amounts after a month finishes. The other rows detail trash amounts given by daily amounts. Finally, there's some other formatting issues we'd like to take care of with the quantitative data (there's no such thing as 6.2 sports balls).

``` r
tidy_trash_data = raw_trash_data %>% 
  janitor::clean_names() %>% 
  filter(., !is.na(.$dumpster)) %>% 
  mutate(sports_balls_int = as.integer(sports_balls)) %>% 
  select(., everything(), -sports_balls)
```

Loading precipitation data
--------------------------

Next, we need to import and start cleaning the precipitation data from 2016 and 2017.

``` r
precip_2016 = read_xlsx('./data/P2/water_wheel.xlsx',
                        sheet = '2016 Precipitation',
                        range = 'A2:B14')

precip_2017 = read_xlsx('./data/P2/water_wheel.xlsx',
                        sheet = '2017 Precipitation',
                        range = 'A2:B14')
```

These data sets originally came in two separate sheets, so they will need to be combined later on. Like the trash data, there are some rows that need to be removed since some data are missing in the 2017 precipitation data. These data look alike, but we need to add a year column before we can append these datasets together. In the case of the 2017 data, we need to remove the `NA` rows. Finally, the month's are coded as numbers and need to be converted to their corresponding month names.

``` r
tidy_precip_2016 = precip_2016 %>% 
  janitor::clean_names() %>% 
  mutate(year = "2016",
         month = month.name) %>% 
  select(., year, month, total)

tidy_precip_2017 = precip_2017 %>% 
  janitor::clean_names() %>% 
  mutate(year = "2017",
         month = month.name) %>% 
  filter(., !is.na(.$total)) %>% 
  select(., year, month, total)

tidy_precipitation = bind_rows(tidy_precip_2016, tidy_precip_2017)
kable(tidy_precipitation)
```

| year | month     |  total|
|:-----|:----------|------:|
| 2016 | January   |   3.23|
| 2016 | February  |   5.32|
| 2016 | March     |   2.24|
| 2016 | April     |   1.78|
| 2016 | May       |   5.19|
| 2016 | June      |   3.20|
| 2016 | July      |   6.09|
| 2016 | August    |   3.96|
| 2016 | September |   4.53|
| 2016 | October   |   0.62|
| 2016 | November  |   1.47|
| 2016 | December  |   2.32|
| 2017 | January   |   2.60|
| 2017 | February  |   1.30|
| 2017 | March     |   3.57|

The end result is a tidy dataset that even Mr. Trash can be proud of.

Discussion of the datasets
--------------------------

In its initial form, the Mr. Trash Wheel dataset had 211 rows, but not all of these were true daily observations. After cleaning, the data has 174 observations. The result is daily information on what kinds of trash Mr. Trash Wheel is picking up. We can see in the `polystyrene` and `sports_balls_int` column that the machine is picking up various items that shouldn't be in the river.

In the beginning the 2016 precipitation dataset had 12 rows, and the 2017 dataset had 12 rows. After all the data cleaning and manipulation, the resulting preciptation data is 15 rows and has more descriptive `year` and `month` descriptions. The `total` column gives us the amount of precipitation on a given `year` and `month`.
